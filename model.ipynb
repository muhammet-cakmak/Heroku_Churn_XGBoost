{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.externals import joblib \n",
    "import pickle\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Churn_Modelling.csv\")\n",
    "\n",
    "df_x = df.iloc[:, 3:13]\n",
    "df_y = df.iloc[:, 13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df):\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    df.Gender = le.fit_transform(df.Gender)\n",
    "    df = pd.get_dummies(data = df, columns=[\"Geography\"], drop_first = False)\n",
    "    df = df.sort_index(axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x = clean_data(df_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_x, df_y, test_size = 0.2, random_state = 0)\n",
    "pickle.dump(df_x.columns, open(\"columns.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.36890377  0.8793029  -0.55204276 ...  0.9687384  -0.92159124\n",
      "   1.04473698]\n",
      " [ 0.10961719  0.42972196 -1.31490297 ... -1.03227043 -0.92159124\n",
      "  -1.031415  ]\n",
      " [ 0.30102557  0.30858264  0.57162971 ...  0.9687384  -0.92159124\n",
      "   1.04473698]\n",
      " ...\n",
      " [-0.27319958  1.29745526 -0.74791227 ... -1.03227043  0.8095029\n",
      "  -1.37744033]\n",
      " [-0.46460796  1.05975239 -0.00566991 ...  0.9687384  -0.92159124\n",
      "  -0.33936434]\n",
      " [-0.84742473  0.82026342 -0.79945688 ... -1.03227043 -0.92159124\n",
      "   1.04473698]]\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "pickle.dump(scaler, open(\"std_scaler.pkl\", 'wb'))\n",
    "print(X_test)\n",
    "print(X_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bytree=1, gamma=0, learning_rate=0.16, max_delta_step=0,\n",
       "              max_depth=50, min_child_weight=1, missing=None, n_estimators=200,\n",
       "              n_jobs=1, nthread=None, objective='binary:logistic',\n",
       "              random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "              seed=None, silent=True, subsample=1)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "model = xgb.XGBClassifier(max_depth=50, min_child_weight=1,  n_estimators=200,learning_rate=0.16)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score,roc_curve,auc\n",
    "predictions = model.predict_proba(X_test)\n",
    "#print (\"\\naccuracy_score :\",accuracy_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.91999733, 0.08000269],\n",
       "       [0.95326316, 0.04673682],\n",
       "       [0.9971275 , 0.00287252],\n",
       "       ...,\n",
       "       [0.99371326, 0.00628672],\n",
       "       [0.89380795, 0.10619205],\n",
       "       [0.9683398 , 0.03166021]], dtype=float32)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model so created above into a picle.\n",
    "pickle.dump(model, open('model.pkl', 'wb')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
